# -*- coding: utf-8 -*-
"""ENGINE LAYER.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1De_KA-dUY99JvldrYVRZibPQ9V7gdONe
"""

import streamlit as st
import matplotlib.pyplot as plt
import seaborn as sns
import geopandas as gpd
import pandas as pd
import numpy as np
import networkx as nx
from sklearn.neighbors import BallTree
from shapely.geometry import Point, MultiPoint
from matplotlib.lines import Line2D
from pysal.explore import esda
from libpysal import weights
from esda.moran import Moran

def run_analysis(facilities_df, road_network, population_tif):

if all_data_with_year:
  merged_data = pd.concat(all_data_with_year, ignore_index=True)
  print(f"Successfully re-merged data with 'Year' column from {len(all_data_with_year)} years. Total rows: {len(merged_data)}")
  display(merged_data.head())
else:
  print("No data was loaded.")

print(merged_data.head())

print(merged_data.columns)

long_data = merged_data.melt(id_vars=["LGA", 'Year'], var_name='Month', value_name='Outpatient_Count')

long_data

long_data["LGA"].unique()

long_data["LGA"]=(
    long_data["LGA"]
    .str.replace("^kd\s+","",regex=True)
    .str.replace("Kaduna State", "State Total", regex=False)
    .str.replace("Local Government Area", "", regex=False)
    .str.strip()
)

long_data["LGA"].unique()

long_data["Month"].unique()

month_map = {
    "January":"Jan",
    "February" : "Feb",
    "March": "Mar",
    "April": "Apr",
    "May": "May",
    "June": "Jun",
    "July": "Jul",
    "August": "Aug",
    "September": "Sep",
    "October": "Oct",
    "November": "Nov",
    "December": "Dec"
}
long_data["Month"]=long_data["Month"].map(month_map)

Data = long_data

# Data Quality Check:
Data.info()
Data.isna().sum()
Data[Data["Outpatient_Count"]<0]

# Annual Outpatient Attendnace per LGA
Annual_attendance = (
    Data.groupby(["LGA", "Year"], as_index=False)
    .agg(
        Annual_outpatient=("Outpatient_Count", "sum")
    )
  )
Annual_attendance

Data.describe().T

Annual_attendance.to_csv("Annual_attendance.csv", index=False)

Annual_attendance.describe().T

# Monthly Average per LGA
Annual_attendance["mean_monthly_outpatient"] = (
    Annual_attendance["Annual_outpatient"] / 12
)
Annual_attendance

# Seasonal profile of each LGA across the year

Monthly_attendance = (
    Data.groupby(["LGA", "Month"], as_index=False)
    .agg(
        mean_monthly_outpatient=("Outpatient_Count", "mean")
    )
  )
Monthly_attendance

Monthly_attendance.to_csv("Monthly_attendance.csv", index=False)

# Seasonal Index
Annual_mean=(Data.groupby("LGA", as_index=False)
             .agg(overall_mean=("Outpatient_Count", "mean"))
             )



Monthly_attendance=Monthly_attendance.merge(Annual_mean, on="LGA", how="left")
Monthly_attendance

# Now, the seasonality index is computed as:
Monthly_attendance["seasonality_index"] = (
    Monthly_attendance["mean_monthly_outpatient"] /
    Monthly_attendance["overall_mean"]
)
Monthly_attendance

month_order = [
    "Jan", "Feb", "Mar", "Apr", "May", "Jun",
    "Jul", "Aug", "Sep", "Oct", "Nov", "Dec"
]
Monthly_attendance["Month"] = pd.Categorical(
    Monthly_attendance["Month"], categories=month_order, ordered=True
)

heatmap_data = Monthly_attendance.pivot(
    index="LGA",
    columns="Month",
    values="seasonality_index"
)


data = heatmap_data.values

plt.figure(figsize=(12, 8))
plt.imshow(data, aspect="auto")

plt.colorbar(label="Seasonality Index")

plt.xticks(
    ticks=np.arange(len(heatmap_data.columns)),
    labels=heatmap_data.columns,
    rotation=45
)

plt.yticks(
    ticks=np.arange(len(heatmap_data.index)),
    labels=heatmap_data.index
)

plt.title("Heatmap of Seasonal Variation in Outpatient Attendance by LGA")
plt.xlabel("Month")
plt.ylabel("Local Government Area")

plt.tight_layout()
plt.show()

# Prepare data grouped by month
boxplot_data = [
    Monthly_attendance.loc[Monthly_attendance["Month"] == month, "seasonality_index"].dropna()
    for month in month_order
]

plt.figure(figsize=(10, 6))
plt.boxplot(boxplot_data, labels=month_order)

plt.axhline(
    y=1.0,
    linestyle="--",
    linewidth=1
)

plt.title("Distribution of Seasonality Index by Month Across LGAs")
plt.xlabel("Month")
plt.ylabel("Seasonality Index")

plt.tight_layout()
plt.show()

LGA_Boundary["Population"] = [stat["sum"] for stat in stats]

Population_data = LGA_Boundary[["NAME_2", "Population"]].copy()
Population_data

# Replication of Population by year
years = Data["Year"].unique()

Population_data=(Population_data.assign(key=1).merge(pd.DataFrame({"Year":years, "key":1}), on="key"
)
.drop("key", axis=1)
)

Data=Data.merge(Population_data, left_on="LGA", right_on="NAME_2", how="left")

Data["Population"].isna().sum()

# Computation of Outpatient Attendance Rate
Data["Outpatient_Attendance_Rate"] = (
    Data["Outpatient_Count"] / Data["Population"]
)*1000

# Trend Analysis by LGA
# Time Index
Data["Month_Index"] = pd.to_datetime(Data["Month"],format="%b").dt.month

Data["date"]=pd.to_datetime(
    dict(year=Data["Year_x"], month=Data["Month_Index"], day=1)
)

Data=Data.sort_values(["NAME_2", "date"])

# Monthly Trend
Monthly_Trend = (Data.groupby(["LGA", "date"], as_index=False)
                 .agg({"Outpatient_Attendance_Rate":"mean"})
                 )

Monthly_Trend.to_excel("Monthly_Trend.xlsx", index=False)

Data_2024 = Monthly_Trend[Monthly_Trend['date'].dt.year == 2024].groupby('LGA')['Outpatient_Attendance_Rate'].mean().reset_index()

merged_LGA_Trend = LGA_Boundary.merge(Data_2024, left_on='NAME_2', right_on='LGA')

w = lp.weights.Queen.from_dataframe(merged_LGA_Trend)
w.transform = 'R'

# Global Moran's I
y = merged_LGA_Trend['Outpatient_Attendance_Rate']
mi = Moran(y, w)

print(f"Moran's I Statistic: {mi.I:.4f}")
print(f"P-value: {mi.p_sim:.4f}")
print(f"Z-score: {mi.z_sim:.4f}")

if mi.p_sim < 0.05:
    result = "Clustered" if mi.I > 0 else "Dispersed"
    print(f"Conclusion: Statistically significant {result} pattern.")
else:
    print("Conclusion: Spatial Randomness (No significant pattern).")

# Comparison of Pre against Post COVID-19 Era
def COVID_period (year):
  if year <= 2019:
    return "Pre-COVID"
  elif year in [2020, 2021]:
    return "COVID-19 Era"
  else:
      return "Post-COVID"
Data["Period"]=Data["Year_x"].apply(COVID_period)



Comparison_period = (Data.groupby(["LGA", "Period"], as_index=False)
                      .agg({"Outpatient_Attendance_Rate":"mean"})
                      )

# Is there any Growth or decline rate?
Annual_rate = (Data.groupby(["LGA", "Year_x"], as_index=False)
               .agg({"Outpatient_Attendance_Rate":"mean"})
               )

Annual_rate["growth_rate"] = Annual_rate.groupby("LGA")["Outpatient_Attendance_Rate"].pct_change().fillna(0) * 100

# SEASONALITY ANALYSIS
Seasonality = (Data.groupby(["LGA", "Month"], as_index=False)
               .agg({"Outpatient_Attendance_Rate":"mean"})
               )
Seasonality

Seasonal_Summary = (Seasonality.groupby("Month", as_index=False)
                    .agg({"Outpatient_Attendance_Rate":"mean"})
                    .sort_values("Outpatient_Attendance_Rate", ascending=False)
                    )

# Dry and Wet Season

def season(month):
  if month in ["Nov", "Dec", "Jan", "Feb"]:
    return "Harmattan"
  elif month in ["Mar", "Apr"]:
    return "Hot-Dry"
  else:
      return "Rainy"

Data["Season"]=Data["Month"].apply(season)

season_effect = (Data.groupby(["LGA", "Season"], as_index=False)
                 .agg({"Outpatient_Attendance_Rate":"mean"})
                 )

# SHOCK ANALYSIS for COVID-19
'''
COVID-19 Anomaly Detection with baseline year = 2019
'''
baseline = (Data[Data["Year_x"]==2019]
            .groupby("Month", as_index=False)
            .agg({"Outpatient_Attendance_Rate":"mean"}))

# Comparing with year 2020

COVID_2020 = (Data[Data["Year_x"]==2020]
              .groupby("Month", as_index=False)
              .agg({"Outpatient_Attendance_Rate":"mean"}))

anomaly=COVID_2020.merge(baseline, on="Month", suffixes=("_2020", "_2019"))

anomaly["deviation_pct"]=(anomaly["Outpatient_Attendance_Rate_2020"]-anomaly["Outpatient_Attendance_Rate_2019"])/anomaly["Outpatient_Attendance_Rate_2019"]*100

anomaly

Data["LGA"]=Data["LGA"].str.strip()

Spatial_data = LGA_Boundary.merge(Data, on="NAME_2", how="left")

Spatial_data["Outpatient_Count"] .isna().sum()

# SPATIAL PATTERN ANALYSIS
# Annual LGA-level Chloropleths

print(Spatial_data.columns)

Spatial_data["geometry"]

type(Spatial_data)

type(Spatial_data["geometry"])

Annual_spatial=(
    Spatial_data.groupby(["NAME_2", "Year_x"], as_index=False)
    .agg({"Outpatient_Count":"mean"})
)

baseline=Annual_spatial[Annual_spatial["Year_x"]==2019][["NAME_2", "Outpatient_Count"]].rename(columns={"Outpatient_Count":"Outpatient_rate_2019"})
endline=Annual_spatial[Annual_spatial["Year_x"]==2020][["NAME_2", "Outpatient_Count"]].rename(columns={"Outpatient_Count":"Outpatient_rate_2020"})

change_map=baseline.merge(endline, on="NAME_2")

change_map

change_map["rate_change"]=change_map["Outpatient_rate_2020"]-change_map["Outpatient_rate_2019"]

change_map=change_map.merge(LGA_Boundary[["NAME_2", "geometry"]], on="NAME_2", how="left")

change_map=gpd.GeoDataFrame(change_map, geometry="geometry")

print(change_map.head())

print(change_map.geometry.is_valid.value_counts())

Annual_spatial=(
    Spatial_data.groupby(["NAME_2", "Year_x"], as_index=False)
    .agg({"Outpatient_Count":"mean"})
)

Annual_spatial=Annual_spatial.merge(LGA_Boundary[["NAME_2", "geometry"]], on="NAME_2", how="left")

Annual_spatial=gpd.GeoDataFrame(Annual_spatial, geometry="geometry")

# Changes in 2019 through 2024
baseline = Annual_spatial[Annual_spatial["Year_x"] == 2019][["NAME_2", "Outpatient_Count"]].rename(columns={"Outpatient_Count": "Outpatient_rate_2019"})
endline = Annual_spatial[Annual_spatial["Year_x"] == 2024][["NAME_2", "Outpatient_Count"]].rename(columns={"Outpatient_Count": "Outpatient_rate_2024"})

change_map=baseline.merge(endline, on="NAME_2")

change_map["rate_change"]=change_map["Outpatient_rate_2024"]-change_map["Outpatient_rate_2019"]

change_map=change_map.merge(LGA_Boundary[["NAME_2", "geometry"]], on="NAME_2", how="left")
change_map=gpd.GeoDataFrame(change_map, geometry="geometry")

# Persistent Low-Attendance LGAs

threshold = Annual_spatial.groupby("Year_x")["Outpatient_Count"].quantile(0.25).mean() # bottom 25% of average rate across all the years.

low_attendance = (Annual_spatial.groupby("NAME_2")["Outpatient_Count"].mean().reset_index())

low_attendance["low_utilization"]=low_attendance["Outpatient_Count"]==threshold

persistent_low=LGA_Boundary.merge(low_attendance, on = "NAME_2", how="left")

persistent_low=gpd.GeoDataFrame(persistent_low, geometry="geometry")

Spatial_data["Month_num"]=Spatial_data["Month"].map({"Jan": 1,"Feb": 2,"Mar": 3,"Apr": 4,"May": 5,"Jun": 6,"Jul": 7,"Aug": 8,"Sep": 9,"Oct": 10,"Nov": 11,"Dec": 12})
Spatial_data["date"]=pd.to_datetime(Spatial_data["Year_x"].astype(str)+"-"+Spatial_data["Month_num"].astype(str)+"-01")

# Hotspot Persistence Analysis

LGA_Stats=Spatial_data.groupby("NAME_2")["Outpatient_Attendance_Rate"].mean().reset_index()

LGA_Stats["Standard Deviation"]=Spatial_data.groupby("NAME_2")["Outpatient_Attendance_Rate"].std().values

# Definition of Persistent High or Low
High_threshold=LGA_Stats["Outpatient_Attendance_Rate"].quantile(0.75)
Low_threshold=LGA_Stats["Outpatient_Attendance_Rate"].quantile(0.25)

LGA_Stats["hotspot_stats"]=LGA_Stats["Outpatient_Attendance_Rate"].apply(lambda x: "High" if x>=High_threshold else ("Low" if x<=Low_threshold else "Medium"))

hotspot_map = LGA_Boundary.merge(LGA_Stats[["NAME_2", "hotspot_stats"]], on="NAME_2")

hotspot_map=gpd.GeoDataFrame(hotspot_map, geometry="geometry")

pivot_table=Spatial_data.pivot_table(index="NAME_2", columns="date", values="Outpatient_Attendance_Rate")

print(Roads.columns)
print(Roads.crs)
print(len(Roads))

Roads = Roads.to_crs(epsg=32632)
LGA_Boundary = LGA_Boundary.to_crs(epsg=32632)

Roads["length_km"] = Roads.geometry.length / 1000

Roads_with_LGA = gpd.sjoin(Roads, LGA_Boundary[['NAME_2', 'geometry']], how="inner", predicate="intersects")

Road_stats = Roads_with_LGA.groupby("NAME_2")["length_km"].sum().reset_index()
Road_stats = Road_stats.rename(columns={"length_km": "Total_road_km"})

LGA_features = LGA_Boundary.merge(Road_stats, on="NAME_2", how="left")
LGA_features["Total_road_km"] = LGA_features["Total_road_km"].fillna(0)

LGA_features = LGA_features.to_crs(epsg=4326)
print(LGA_features[['NAME_2', 'Total_road_km']].head())

def create_isochrones(Roads, Facilities, time_thresholds=[30, 60], speed_kmh=30):
    print("Pre-processing road network...")

    roads = Roads.explode(index_parts=False).to_crs(epsg=32632)
    facilities = Facilities.to_crs(epsg=32632)

    # Travel Time calculation: (Length in km / Speed) * 60 minutes
    roads['travel_time_min'] = (roads.geometry.length / 1000 / speed_kmh) * 60

    # Building the Network Graph
    G = nx.Graph()
    for _, row in roads.iterrows():
        if row.geometry.geom_type == 'LineString':
            coords = list(row.geometry.coords)
            # Connection of the start and end nodes of each road segment
            G.add_edge(coords[0], coords[-1], weight=row['travel_time_min'])

    # Building the Spatial Index for fast "nearest road" lookup
    nodes = list(G.nodes)
    node_coords = np.array(nodes)
    tree = BallTree(node_coords)

    isochrone_results = []
    total = len(facilities)

    print(f"Starting network analysis for {total} facilities...")

    for i, (idx, feat) in enumerate(facilities.iterrows()):

        if (i + 1) % 50 == 0 or (i + 1) == total:
            print(f"Progress: {i + 1}/{total} facilities processed...")

        f_geom = feat.geometry
        f_point = np.array([[f_geom.x, f_geom.y]])

        _, node_idx = tree.query(f_point, k=1)
        nearest_node = nodes[node_idx[0][0]]

        for time_limit in time_thresholds:

            subgraph = nx.ego_graph(G, nearest_node, radius=time_limit, distance='weight')
            node_pts = [Point(n) for n in subgraph.nodes]

            if len(node_pts) > 2:

                poly = MultiPoint(node_pts).convex_hull
                isochrone_results.append({
                    'facility_name': feat.get('NAME', 'Facility'),
                    'time_limit': time_limit,
                    'geometry': poly
                })

    return gpd.GeoDataFrame(isochrone_results, crs=32632).to_crs(epsg=4326)

isochrones_gdf = create_isochrones(Roads, Facilities)

# Dissolving 60-minute coverage areas
print("Merging coverage areas using union_all()...")
isochrones_60min = isochrones_gdf[isochrones_gdf['time_limit'] == 60].copy()

isochrones_60min['geometry'] = isochrones_60min.geometry.buffer(0)
coverage_60min_union = isochrones_60min.geometry.union_all()

print("Calculating healthcare deserts...")
LGA_Boundary_4326 = LGA_Boundary.to_crs(epsg=4326)

coverage_df = gpd.GeoDataFrame(geometry=[coverage_60min_union], crs=4326)

healthcare_deserts = gpd.overlay(
    LGA_Boundary_4326,
    coverage_df,
    how='difference'
)

print("\n--- ANALYSIS COMPLETE ---")

LGA_metric = LGA_Boundary.to_crs(epsg=32632)
deserts_metric = healthcare_deserts.to_crs(epsg=32632)

LGA_metric['total_area_km2'] = LGA_metric.geometry.area / 1e6

desert_fragments = gpd.overlay(deserts_metric, LGA_metric, how='intersection')

desert_fragments['desert_area_km2'] = desert_fragments.geometry.area / 1e6

possible_names = ['NAME_2', 'name_2', 'LGA', 'lga']
found_name = next((name for name in possible_names if name in desert_fragments.columns), desert_fragments.columns[0])
print(f"Grouping by column: {found_name}")

summary_table = desert_fragments.groupby(found_name).agg({
    'total_area_km2': 'first',
    'desert_area_km2': 'sum'
}).reset_index()

summary_table['pct_underserved'] = (summary_table['desert_area_km2'] / summary_table['total_area_km2']) * 100
summary_table = summary_table.sort_values(by='pct_underserved', ascending=False)

summary_table = summary_table.rename(columns={found_name: 'NAME_2'})

print(summary_table[['NAME_2', 'pct_underserved']].head(10))

lga_list = Monthly_Trend["LGA"].unique()
selected_lga = st.selectbox("Select an LGA to visualize trends:", options=lga_list)

subset = Monthly_Trend[Monthly_Trend["LGA"] == selected_lga]

fig, ax = plt.subplots(figsize=(12, 6))
sns.lineplot(data=subset, x="date", y="Outpatient_Attendance_Rate", marker="o", ax=ax)

plt.title(f"Monthly Trend for {selected_lga}")
plt.xlabel("Date")
plt.ylabel("Outpatient Attendance Rate for {selected_lga}")
plt.xticks(rotation=45)

st.pyplot(fig)

available_years = sorted(Annual_spatial["Year_x"].unique())

year_to_plot = st.select_slider("Select Year to Visualize Spatial Trends:", options=available_years)

subset = Annual_spatial[Annual_spatial["Year_x"] == year_to_plot]

fig, ax = plt.subplots(1, 1, figsize=(10, 8))

subset.plot(
    column="Outpatient_Count",
    cmap="YlOrRd",
    linewidth=0.8,
    legend=True,
    ax=ax,
    edgecolor="black",
    legend_kwds={'label': "Outpatient Count", 'orientation': "horizontal"}
)

ax.axis("off")
ax.set_title(f"Spatial Distribution of Outpatient Rate in Kaduna State: {year_to_plot}", fontsize=15)
st.pyplot(fig)

fig, ax=plt.subplots(1,1, figsize=(10,8))
change_map.plot(column="rate_change", cmap="RdBu", linewidth=0.8, legend=True, ax=ax, edgecolor="black")
ax.set_title("Change in Outpatient Attendance Rate (2019 - 2024)")
ax.axis("off")
st.pyplt(fig)

fig, ax=plt.subplots(1, 1, figsize=(10,8))
persistent_low.plot(column="low_utilization", cmap="coolwarm", linewidth=0.8, legend=True, ax=ax, edgecolor="black")
ax.set_title("Persistent Low-Attendance by LGAs (2019 - 2024)")
ax.axis("off")
st.pyplt(fig)

fig, ax=plt.subplots(1,1,figsize=(10,8))
hotspot_map.plot(column="hotspot_stats", cmap="coolwarm", linewidth=0.8, legend=True, ax=ax, edgecolor="black")
ax.set_title("Persistent Outpatient Attendance Hotspots (2019 - 2024)")
ax.axis("off")
st.pyplt(fig)

st.subheader("Spatiotemporal Attendance Heatmap")

all_lgas = pivot_table.index.tolist()
selected_lgas = st.multiselect(
    "Select LGAs to include in Heatmap:",
    options=all_lgas,
    default=all_lgas[:10] # Defaults to the first 10 for better visibility
)

filtered_pivot = pivot_table.loc[selected_lgas]

fig, ax = plt.subplots(figsize=(15, 10))
sns.heatmap(filtered_pivot, cmap="YlOrRd", linewidths=0.5, ax=ax)

plt.title("Outpatient Attendance Heatmap per LGA (2019 - 2024)", fontsize=16)
plt.xlabel("Month-Year", fontsize=12)
plt.ylabel("LGA", fontsize=12)

st.pyplot(fig)

st.subheader("Interactive Spatiotemporal Attendance Heatmap")

available_lgas = pivot_table.index.tolist()
selected_lgas = st.multiselect(
    "Filter LGAs for Detail View:",
    options=available_lgas,
    default=available_lgas[:22] # Default to the first 12 for readability
)

if selected_lgas:
    filtered_pivot = pivot_table.loc[selected_lgas]

    fig, ax = plt.subplots(figsize=(15, 10))
    sns.heatmap(filtered_pivot, cmap="YlOrRd", linewidths=0.5, ax=ax)

    plt.title(f"Outpatient Attendance Heatmap for Selected LGAs (2019 - 2024)", fontsize=16)
    plt.xlabel("Month-Year", fontsize=12)
    plt.ylabel("Local Government Area (LGA)", fontsize=12)

    st.pyplot(fig)

    st.info("The darker red intensity indicates months with significantly higher outpatient attendance rates.")
else:
    st.warning("Please select at least one LGA to view the heatmap.")

st.subheader("Interactive Healthcare Accessibility & Desert Map")
Facilities_4326 = Facilities.to_crs(epsg=4326)
LGA_Boundary_4326 = LGA_Boundary.to_crs(epsg=4326)

fig, ax = plt.subplots(figsize=(12, 12))

LGA_Boundary_4326.plot(ax=ax, color='white', edgecolor='#666666', linewidth=0.8, zorder=1)

healthcare_deserts.plot(ax=ax, color='#ffcccc', zorder=2)

# 60-min coverage (Green)
isochrones_gdf[isochrones_gdf['time_limit'] == 60].plot(ax=ax, color='#2ca02c', alpha=0.3, zorder=3)
# 30-min coverage (Blue)
isochrones_gdf[isochrones_gdf['time_limit'] == 30].plot(ax=ax, color='#1f77b4', alpha=0.5, zorder=4)

# Layer 4: Facilities (Red Crosses)
Facilities_4326.plot(ax=ax, color='red', markersize=8, marker='+', zorder=5)

ax.set_title('Public Health Facility Accessibility and Deserts in Kaduna State', fontsize=16, fontweight='bold')
ax.set_axis_off()

legend_elements = [
    Line2D([0], [0], color='#666666', lw=1, label='LGA Boundary'),
    Line2D([0], [0], marker='s', color='w', label='Healthcare Desert (>60 min)', markerfacecolor='#ffcccc', markersize=15),
    Line2D([0], [0], marker='s', color='w', label='60-min Service Area', markerfacecolor='#2ca02c', alpha=0.3, markersize=15),
    Line2D([0], [0], marker='s', color='w', label='30-min Service Area', markerfacecolor='#1f77b4', alpha=0.5, markersize=15),
    Line2D([0], [0], marker='+', color='red', label='Health Facility', markersize=10, ls='')
]
ax.legend(handles=legend_elements, loc='lower right', title="Accessibility Metrics")

plt.tight_layout()

st.pyplot(fig)

with st.expander("View Accessibility Insights"):
    st.write("""
    - **Blue Zones:** Optimal access (within 30 mins).
    - **Green Zones:** Acceptable access (30-60 mins).
    - **Pink Zones (Deserts):** Critical concern. These areas represent populations living more than 1 hour away from a public facility.
    """)

results = "Analysis Complete"
    return results # This sends the data back to the dashboard

def calculate_priority_recommendations(LGA_Boundary, healthcare_deserts):
    LGA_proj = LGA_Boundary.to_crs(epsg=32632)
    deserts_proj = healthcare_deserts.to_crs(epsg=32632)

    priority_data = []
    for _, lga in LGA_proj.iterrows():
        lga_gap = deserts_proj.clip(lga.geometry)
        gap_area_km2 = lga_gap.area.sum() / 10**6

        status = "ðŸ”´ HIGH" if gap_area_km2 > 500 else "ðŸŸ¡ MEDIUM" if gap_area_km2 > 150 else "ðŸŸ¢ LOW"
        priority_data.append({
            "LGA Name": lga['LGA_NAME'],
            "Underserved Area (kmÂ²)": round(gap_area_km2, 2),
            "Priority Status": status
        })

    priority_df = pd.DataFrame(priority_data).sort_values(by="Underserved Area (kmÂ²)", ascending=False)
    return priority_df

    deserts_exploded = healthcare_deserts.explode(index_parts=False)
    top_5_gaps = deserts_exploded.sort_values(by=deserts_exploded.area, ascending=False).head(5)

    proposed_sites = []
    for i, geom in enumerate(top_5_gaps.geometry):
        proposed_sites.append({
            "Latitude": round(geom.centroid.y, 6),
            "Longitude": round(geom.centroid.x, 6)
        })