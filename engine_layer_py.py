# -*- coding: utf-8 -*-
"""ENGINE LAYER.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1De_KA-dUY99JvldrYVRZibPQ9V7gdONe
"""

import streamlit as st
import geopandas as gpd
import pandas as pd
import numpy as np
import re
from rasterstats import zonal_stats
import tempfile, os
import libpysal as lp
from esda.moran import Moran

def run_analysis(facilities_df, roads_df, lga_boundary, outpatient_files, population_tif):
    try:
        # 1. Coordinate Alignment & Population Extraction
        lga_boundary = lga_boundary.to_crs(epsg=4326)
        with tempfile.NamedTemporaryFile(suffix='.tif', delete=False) as tmp:
            tmp.write(population_tif.read())
            tmp_path = tmp.name
        
        # Extracting population sum per LGA
        stats = zonal_stats(lga_boundary, tmp_path, stats=["sum"])
        lga_boundary["Population"] = [max(s["sum"], 1) if s and s["sum"] else 5000 for s in stats]
        os.unlink(tmp_path)
        
        # 2. Cleanup LGA Names for merging
        # Note: Using 'NAME_2' based on your shapefile standard
        lga_boundary["NAME_UP"] = lga_boundary["NAME_2"].str.strip().str.upper()

        # 3. Consolidate Outpatient Data
        all_data = []
        for file in outpatient_files:
            df = pd.read_excel(file)
            if 'Year' not in df.columns:
                match = re.search(r'(\d{4})', file.name)
                df['Year'] = int(match.group(1)) if match else 2024
            
            # Replicating your cleaning logic
            df["LGA_CLEAN"] = df["LGA"].astype(str).str.replace("^kd\s+", "", regex=True, case=False).str.strip().str.upper()
            all_data.append(df)
        
        raw_df = pd.concat(all_data, ignore_index=True)
        month_cols = ["January", "February", "March", "April", "May", "June", 
                      "July", "August", "September", "October", "November", "December"]
        
        # Create annual maps
        annual_maps = {}
        for yr in sorted(raw_df['Year'].unique()):
            yr_df = raw_df[raw_df['Year'] == yr].copy()
            yr_df['Total_Yearly'] = yr_df[month_cols].sum(axis=1)
            agg = yr_df.groupby('LGA_CLEAN')['Total_Yearly'].sum().reset_index()
            
            merged = lga_boundary.merge(agg, left_on="NAME_UP", right_on="LGA_CLEAN", how="left").fillna(0)
            merged[f'Rate_{yr}'] = (merged['Total_Yearly'] / merged['Population']) * 1000
            annual_maps[yr] = merged

        # 4. Seasonal Analysis
        long_df = raw_df.melt(id_vars=["LGA_CLEAN", "Year"], value_vars=month_cols, var_name='Month', value_name='Count')
        long_df = long_df.merge(lga_boundary[['NAME_UP', 'Population']], left_on='LGA_CLEAN', right_on='NAME_UP')
        long_df['Rate'] = (long_df['Count'] / long_df['Population']) * 1000
        
        def get_season(m):
            if m in ["November", "December", "January", "February"]: return "Harmattan"
            if m in ["March", "April"]: return "Hot-Dry"
            return "Rainy Season"
        
        long_df['Season'] = long_df['Month'].apply(get_season)
        seasonal_table = long_df.groupby(['LGA_CLEAN', 'Season'])['Rate'].mean().unstack().reset_index()

        # 5. Global Moran's I (-0.2554 replication)
        latest_yr = max(annual_maps.keys())
        map_for_moran = annual_maps[latest_yr]
        w = lp.weights.Queen.from_dataframe(map_for_moran)
        w.transform = 'R'
        mi = Moran(map_for_moran[f'Rate_{latest_yr}'], w)

        # 6. Road Network & Facility Deserts
        # Buffer facilities by 30km (UTM 32N for meter accuracy)
        fac_metric = facilities_df.to_crs(epsg=32632)
        lga_metric = lga_boundary.to_crs(epsg=32632)
        coverage = fac_metric.buffer(30000).union_all()
        deserts = gpd.overlay(lga_metric, gpd.GeoDataFrame(geometry=[coverage], crs=32632), how='difference')
        
        return annual_maps, seasonal_table, mi, deserts, lga_boundary
    except Exception as e:
        return None, None, None, None, str(e)
